{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nprint(\"PyTorch Version: \",torch.__version__)\nprint(\"Torchvision Version: \",torchvision.__version__)\ninput_size = (224,224)\nbatch_size = 8\n\ncriterion = nn.CrossEntropyLoss()\n# Data Transformations\n\ndata_dir = '../input/vgg-data/z'\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nprint(\"Initializing Datasets and Dataloaders...\")\n\n# Create training and validation datasets\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# Create training and validation dataloaders\ndataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\nprint(len(image_datasets['train'])) # Number of training images\nprint(len(dataloaders_dict['train'])) # Equal to #Training images / Batch Size\nprint(len(dataloaders_dict['train'].dataset)) # Also equal to number of training images\nprint(len(image_datasets['train'])/batch_size) # Equal to #Training images / Batch Size\ndata = next(iter(dataloaders_dict['train']))\nprint(len(data[0]),\"1\") \n#print(dataloaders_dict['train'][0])\n# Detect if we have a GPU available\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nclass_names = image_datasets['train'].classes\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-22T14:55:41.949398Z","iopub.execute_input":"2022-06-22T14:55:41.950366Z","iopub.status.idle":"2022-06-22T14:55:43.319287Z","shell.execute_reply.started":"2022-06-22T14:55:41.950317Z","shell.execute_reply":"2022-06-22T14:55:43.318145Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"PyTorch Version:  1.11.0\nTorchvision Version:  0.12.0\nInitializing Datasets and Dataloaders...\n2038\n255\n2038\n254.75\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"},{"name":"stdout","text":"8 1\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"vgg\"\n\n# Number of classes in the dataset\nnum_classes = 18\n\n# Batch size for training (change depending on how much memory you have)\nbatch_size = 8\n\n# Number of epochs to train for\nnum_epochs = 15\n\n# Flag for feature extracting. When False, we finetune the whole model,\n#   when True we only update the reshaped layer params\nfeature_extract = True","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:55:53.162675Z","iopub.execute_input":"2022-06-22T14:55:53.163061Z","iopub.status.idle":"2022-06-22T14:55:53.170512Z","shell.execute_reply.started":"2022-06-22T14:55:53.163025Z","shell.execute_reply":"2022-06-22T14:55:53.169506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss\")\n#plt.plot(train_losses,label=\"train\")\n\n\n\n\n\n\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n    loss_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n     # Iterates over # of epochs\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            # If phase equals train, then the model(resnet, vgg, etc.) is put into train mode\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            \n            for inputs, labels in dataloaders[phase]:\n                #print(phase)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n          #  len(dataloaders_dict['train'].dataset = Total num img in training set\n           #  len(dataloaders_dict['val'].dataset = Total num img in val set\n            # The phase variable is either val or train and represents that repsective data set\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                loss_history.append(epoch_loss)\n\n        #print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    plt.plot(loss_history)\n    plt.plot(val_acc_history)\n    return model, val_acc_history\n#print(image_datasets.dataset)\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:56:14.928604Z","iopub.execute_input":"2022-06-22T14:56:14.929127Z","iopub.status.idle":"2022-06-22T14:56:15.136322Z","shell.execute_reply.started":"2022-06-22T14:56:14.929090Z","shell.execute_reply":"2022-06-22T14:56:15.135389Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"def set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:56:31.830300Z","iopub.execute_input":"2022-06-22T14:56:31.831183Z","iopub.status.idle":"2022-06-22T14:56:31.836288Z","shell.execute_reply.started":"2022-06-22T14:56:31.831146Z","shell.execute_reply":"2022-06-22T14:56:31.834833Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n    # Initialize these variables which will be set in this if statement. Each of these\n    #   variables is model specific.\n    model_ft = None\n    input_size = 0\n\n    if model_name == \"resnet\":\n        \"\"\" Resnet18\n        \"\"\"\n        model_ft = models.resnet18(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"alexnet\":\n        \"\"\" Alexnet\n        \"\"\"\n        model_ft = models.alexnet(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"vgg\":\n        \"\"\" VGG11_bn\n        \"\"\"\n        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier[6].in_features\n        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n        input_size = 224\n\n    elif model_name == \"squeezenet\":\n        \"\"\" Squeezenet\n        \"\"\"\n        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n        \n        model_ft.num_classes = num_classes\n        input_size = 224\n\n    elif model_name == \"densenet\":\n        \"\"\" Densenet\n        \"\"\"\n        model_ft = models.densenet121(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        num_ftrs = model_ft.classifier.in_features\n        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n        input_size = 224\n\n    elif model_name == \"inception\":\n        \"\"\" Inception v3\n        Be careful, expects (299,299) sized images and has auxiliary output\n        \"\"\"\n        model_ft = models.inception_v3(pretrained=use_pretrained)\n        set_parameter_requires_grad(model_ft, feature_extract)\n        # Handle the auxilary net\n        num_ftrs = model_ft.AuxLogits.fc.in_features\n        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n        # Handle the primary net\n        num_ftrs = model_ft.fc.in_features\n        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n        input_size = 299\n\n    else:\n        print(\"Invalid model name, exiting...\")\n        exit()\n\n    return model_ft, input_size\n\n# Initialize the model for this run\nmodel_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n\n# Print the model we just instantiated\nprint(model_ft)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:56:41.411673Z","iopub.execute_input":"2022-06-22T14:56:41.412109Z","iopub.status.idle":"2022-06-22T14:56:53.387974Z","shell.execute_reply.started":"2022-06-22T14:56:41.412076Z","shell.execute_reply":"2022-06-22T14:56:53.386517Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg11_bn-6002323d.pth\" to /root/.cache/torch/hub/checkpoints/vgg11_bn-6002323d.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/507M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"024b47444e5847faaccd3d14b970f133"}},"metadata":{}},{"name":"stdout","text":"VGG(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): ReLU(inplace=True)\n    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): ReLU(inplace=True)\n    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): ReLU(inplace=True)\n    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (24): ReLU(inplace=True)\n    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (27): ReLU(inplace=True)\n    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n  (classifier): Sequential(\n    (0): Linear(in_features=25088, out_features=4096, bias=True)\n    (1): ReLU(inplace=True)\n    (2): Dropout(p=0.5, inplace=False)\n    (3): Linear(in_features=4096, out_features=4096, bias=True)\n    (4): ReLU(inplace=True)\n    (5): Dropout(p=0.5, inplace=False)\n    (6): Linear(in_features=4096, out_features=18, bias=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Send the model to GPU\ndevice = \"cuda\"\nmodel_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:57:22.206781Z","iopub.execute_input":"2022-06-22T14:57:22.207163Z","iopub.status.idle":"2022-06-22T14:57:25.344212Z","shell.execute_reply.started":"2022-06-22T14:57:22.207133Z","shell.execute_reply":"2022-06-22T14:57:25.341721Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Params to learn:\n\t classifier.6.weight\n\t classifier.6.bias\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:57:32.908824Z","iopub.execute_input":"2022-06-22T14:57:32.909416Z","iopub.status.idle":"2022-06-22T14:57:32.914806Z","shell.execute_reply.started":"2022-06-22T14:57:32.909377Z","shell.execute_reply":"2022-06-22T14:57:32.913862Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=25, is_inception=(model_name==\"inception\"))","metadata":{"execution":{"iopub.status.busy":"2022-06-22T14:57:41.288035Z","iopub.execute_input":"2022-06-22T14:57:41.288385Z","iopub.status.idle":"2022-06-22T15:07:53.546007Z","shell.execute_reply.started":"2022-06-22T14:57:41.288354Z","shell.execute_reply":"2022-06-22T15:07:53.544462Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch 0/24\n----------\ntrain Loss: 1.5394 Acc: 0.5123\nval Loss: 0.9891 Acc: 0.7307\nEpoch 1/24\n----------\ntrain Loss: 0.9120 Acc: 0.7120\nval Loss: 0.8170 Acc: 0.7557\nEpoch 2/24\n----------\ntrain Loss: 0.7340 Acc: 0.7753\nval Loss: 0.7127 Acc: 0.7975\nEpoch 3/24\n----------\ntrain Loss: 0.6429 Acc: 0.8086\nval Loss: 0.7122 Acc: 0.7891\nEpoch 4/24\n----------\ntrain Loss: 0.5846 Acc: 0.8204\nval Loss: 0.6163 Acc: 0.8288\nEpoch 5/24\n----------\ntrain Loss: 0.5398 Acc: 0.8273\nval Loss: 0.5670 Acc: 0.8267\nEpoch 6/24\n----------\ntrain Loss: 0.4858 Acc: 0.8513\nval Loss: 0.5528 Acc: 0.8351\nEpoch 7/24\n----------\ntrain Loss: 0.4786 Acc: 0.8459\nval Loss: 0.5411 Acc: 0.8580\nEpoch 8/24\n----------\ntrain Loss: 0.4175 Acc: 0.8827\nval Loss: 0.5032 Acc: 0.8476\nEpoch 9/24\n----------\ntrain Loss: 0.4334 Acc: 0.8582\nval Loss: 0.4941 Acc: 0.8476\nEpoch 10/24\n----------\ntrain Loss: 0.4178 Acc: 0.8646\nval Loss: 0.5040 Acc: 0.8559\nEpoch 11/24\n----------\ntrain Loss: 0.3998 Acc: 0.8739\nval Loss: 0.5000 Acc: 0.8622\nEpoch 12/24\n----------\ntrain Loss: 0.3572 Acc: 0.8906\nval Loss: 0.4979 Acc: 0.8559\nEpoch 13/24\n----------\ntrain Loss: 0.3575 Acc: 0.8901\nval Loss: 0.5082 Acc: 0.8727\nEpoch 14/24\n----------\ntrain Loss: 0.3678 Acc: 0.8798\nval Loss: 0.4957 Acc: 0.8727\nEpoch 15/24\n----------\ntrain Loss: 0.3466 Acc: 0.8979\nval Loss: 0.4731 Acc: 0.8559\nEpoch 16/24\n----------\ntrain Loss: 0.3479 Acc: 0.8871\nval Loss: 0.4752 Acc: 0.8518\nEpoch 17/24\n----------\ntrain Loss: 0.3322 Acc: 0.8950\nval Loss: 0.4845 Acc: 0.8518\nEpoch 18/24\n----------\ntrain Loss: 0.3272 Acc: 0.8955\nval Loss: 0.5045 Acc: 0.8476\nEpoch 19/24\n----------\ntrain Loss: 0.3094 Acc: 0.8965\nval Loss: 0.5050 Acc: 0.8643\nEpoch 20/24\n----------\ntrain Loss: 0.3073 Acc: 0.8965\nval Loss: 0.4953 Acc: 0.8601\nEpoch 21/24\n----------\ntrain Loss: 0.3130 Acc: 0.8935\nval Loss: 0.4938 Acc: 0.8727\nEpoch 22/24\n----------\ntrain Loss: 0.3043 Acc: 0.9053\nval Loss: 0.4638 Acc: 0.8810\nEpoch 23/24\n----------\ntrain Loss: 0.2929 Acc: 0.9078\nval Loss: 0.5034 Acc: 0.8351\nEpoch 24/24\n----------\ntrain Loss: 0.2996 Acc: 0.8989\nval Loss: 0.4964 Acc: 0.8559\nTraining complete in 10m 12s\nBest val Acc: 0.881002\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_34/1651744455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_34/3958468919.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_wts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;31m#print(image_datasets.dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     return gca().plot(\n\u001b[1;32m   2770\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2771\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \"\"\"\n\u001b[1;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mindex_of\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m         \u001b[0;31m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpack_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."],"ename":"TypeError","evalue":"can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}