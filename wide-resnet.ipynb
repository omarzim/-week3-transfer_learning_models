{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-22T15:43:45.190329Z","iopub.execute_input":"2022-06-22T15:43:45.193443Z","iopub.status.idle":"2022-06-22T15:43:45.200046Z","shell.execute_reply.started":"2022-06-22T15:43:45.193392Z","shell.execute_reply":"2022-06-22T15:43:45.199086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'wide_resnet101_2', pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:43:47.340765Z","iopub.execute_input":"2022-06-22T15:43:47.341138Z","iopub.status.idle":"2022-06-22T15:43:49.646963Z","shell.execute_reply.started":"2022-06-22T15:43:47.341106Z","shell.execute_reply":"2022-06-22T15:43:49.645996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extract = True\ndef set_parameter_requires_grad(model, feature_extracting):\n    if feature_extracting:\n        for param in model.parameters():\n            param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:43:51.985189Z","iopub.execute_input":"2022-06-22T15:43:51.986085Z","iopub.status.idle":"2022-06-22T15:43:51.991580Z","shell.execute_reply.started":"2022-06-22T15:43:51.986029Z","shell.execute_reply":"2022-06-22T15:43:51.990123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set_parameter_requires_grad(model_ft, feature_extract)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:23.390978Z","iopub.execute_input":"2022-06-22T15:44:23.391628Z","iopub.status.idle":"2022-06-22T15:44:23.397691Z","shell.execute_reply.started":"2022-06-22T15:44:23.391590Z","shell.execute_reply":"2022-06-22T15:44:23.396554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nnum_classes = 18\nnum_ftrs = model_ft.fc.in_features\nprint(num_ftrs)\nmodel_ft.fc = nn.Linear(num_ftrs, num_classes)\ninput_size = 224","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:25.771615Z","iopub.execute_input":"2022-06-22T15:44:25.772564Z","iopub.status.idle":"2022-06-22T15:44:25.781528Z","shell.execute_reply.started":"2022-06-22T15:44:25.772516Z","shell.execute_reply":"2022-06-22T15:44:25.780521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nfrom __future__ import division\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\n#print(\"PyTorch Version: \",torch.__version__)\n#print(\"Torchvision Version: \",torchvision.__version__)\ninput_size = (224,224)\nbatch_size = 8\n\ncriterion = nn.CrossEntropyLoss()\n# Data Transformations\n\ndata_dir = '../input/vgg-data/z'\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\nprint(\"Initializing Datasets and Dataloaders...\")\n\n# Create training and validation datasets\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n# Create training and validation dataloaders\ndataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\nprint(len(image_datasets['train'])) # Number of training images\nprint(len(dataloaders_dict['train'])) # Equal to #Training images / Batch Size\nprint(len(dataloaders_dict['train'].dataset)) # Also equal to number of training images\nprint(len(image_datasets['train'])/batch_size) # Equal to #Training images / Batch Size\ndata = next(iter(dataloaders_dict['train']))\nprint(len(data[0]),\"1\") \n#print(dataloaders_dict['train'][0])\n# Detect if we have a GPU available\n#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nclass_names = image_datasets['train'].classes\n","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:27.346104Z","iopub.execute_input":"2022-06-22T15:44:27.346768Z","iopub.status.idle":"2022-06-22T15:44:28.231570Z","shell.execute_reply.started":"2022-06-22T15:44:27.346733Z","shell.execute_reply":"2022-06-22T15:44:28.230308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 8","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:32.661186Z","iopub.execute_input":"2022-06-22T15:44:32.661547Z","iopub.status.idle":"2022-06-22T15:44:32.666392Z","shell.execute_reply.started":"2022-06-22T15:44:32.661516Z","shell.execute_reply":"2022-06-22T15:44:32.665115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:44.185525Z","iopub.execute_input":"2022-06-22T15:44:44.186189Z","iopub.status.idle":"2022-06-22T15:44:44.192220Z","shell.execute_reply.started":"2022-06-22T15:44:44.186152Z","shell.execute_reply":"2022-06-22T15:44:44.191121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss\")\n#plt.plot(train_losses,label=\"train\")\n\n\n\n\n\n\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n    since = time.time()\n\n    val_acc_history = []\n    loss_history = []\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n     # Iterates over # of epochs\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            # If phase equals train, then the model(resnet, vgg, etc.) is put into train mode\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            \n            for inputs, labels in dataloaders[phase]:\n                #print(phase)\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    # Get model outputs and calculate loss\n                    # Special case for inception because in training it has an auxiliary output. In train\n                    #   mode we calculate the loss by summing the final output and the auxiliary output\n                    #   but in testing we only consider the final output.\n                    if is_inception and phase == 'train':\n                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n                        outputs, aux_outputs = model(inputs)\n                        loss1 = criterion(outputs, labels)\n                        loss2 = criterion(aux_outputs, labels)\n                        loss = loss1 + 0.4*loss2\n                    else:\n                        outputs = model(inputs)\n                        loss = criterion(outputs, labels)\n\n                    _, preds = torch.max(outputs, 1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n          #  len(dataloaders_dict['train'].dataset = Total num img in training set\n           #  len(dataloaders_dict['val'].dataset = Total num img in val set\n            # The phase variable is either val or train and represents that repsective data set\n            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n            if phase == 'val':\n                val_acc_history.append(epoch_acc)\n                loss_history.append(epoch_loss)\n\n        #print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    plt.plot(loss_history)\n    return model, val_acc_history\n#print(image_datasets.dataset)\nplt.xlabel(\"iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:36.074567Z","iopub.execute_input":"2022-06-22T15:44:36.074929Z","iopub.status.idle":"2022-06-22T15:44:36.261111Z","shell.execute_reply.started":"2022-06-22T15:44:36.074895Z","shell.execute_reply":"2022-06-22T15:44:36.260100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Send the model to GPU\n#device = \"cuda\"\nmodel_ft = model_ft.to(device)\n\n# Gather the parameters to be optimized/updated in this run. If we are\n#  finetuning we will be updating all parameters. However, if we are\n#  doing feature extract method, we will only update the parameters\n#  that we have just initialized, i.e. the parameters with requires_grad\n#  is True.\nparams_to_update = model_ft.parameters()\nprint(\"Params to learn:\")\nif feature_extract:\n    params_to_update = []\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            params_to_update.append(param)\n            print(\"\\t\",name)\nelse:\n    for name,param in model_ft.named_parameters():\n        if param.requires_grad == True:\n            print(\"\\t\",name)\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:52.278252Z","iopub.execute_input":"2022-06-22T15:44:52.278794Z","iopub.status.idle":"2022-06-22T15:44:52.299365Z","shell.execute_reply.started":"2022-06-22T15:44:52.278759Z","shell.execute_reply":"2022-06-22T15:44:52.298280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T15:44:54.709109Z","iopub.execute_input":"2022-06-22T15:44:54.709481Z","iopub.status.idle":"2022-06-22T15:44:54.716101Z","shell.execute_reply.started":"2022-06-22T15:44:54.709449Z","shell.execute_reply":"2022-06-22T15:44:54.714808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=25, is_inception=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:18:38.153377Z","iopub.execute_input":"2022-06-22T16:18:38.153652Z","iopub.status.idle":"2022-06-22T16:30:52.398328Z","shell.execute_reply.started":"2022-06-22T16:18:38.153621Z","shell.execute_reply":"2022-06-22T16:30:52.397127Z"},"trusted":true},"execution_count":null,"outputs":[]}]}